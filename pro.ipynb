{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import sys\n",
    "sys.path.append('./TuRBO')  # Adjust this path\n",
    "import torch\n",
    "from turbo import Turbo1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction Hash_len</th>\n",
       "      <th>Original_len</th>\n",
       "      <th>signature_len</th>\n",
       "      <th>From_len</th>\n",
       "      <th>To_len</th>\n",
       "      <th>sender_len</th>\n",
       "      <th>paymaster_len</th>\n",
       "      <th>Txn Fee</th>\n",
       "      <th>Gas Used</th>\n",
       "      <th>logIndex</th>\n",
       "      <th>actualGasCost</th>\n",
       "      <th>actualGasUsed</th>\n",
       "      <th>nonce</th>\n",
       "      <th>success</th>\n",
       "      <th>Blockno</th>\n",
       "      <th>DateTime_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>964</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>398741</td>\n",
       "      <td>245</td>\n",
       "      <td>2.190000e+16</td>\n",
       "      <td>397164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17066994</td>\n",
       "      <td>1681740540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>868</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>87702</td>\n",
       "      <td>231</td>\n",
       "      <td>4.280000e+15</td>\n",
       "      <td>86113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17067000</td>\n",
       "      <td>1681740600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>868</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>87714</td>\n",
       "      <td>273</td>\n",
       "      <td>3.900000e+15</td>\n",
       "      <td>86125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17067009</td>\n",
       "      <td>1681740720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1188</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>161702</td>\n",
       "      <td>429</td>\n",
       "      <td>8.650000e+15</td>\n",
       "      <td>161161</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17078992</td>\n",
       "      <td>1681887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1188</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>127502</td>\n",
       "      <td>393</td>\n",
       "      <td>6.420000e+15</td>\n",
       "      <td>126973</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17079029</td>\n",
       "      <td>1681887420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction Hash_len  Original_len  signature_len  From_len  To_len  \\\n",
       "0                    32           964              4        20      20   \n",
       "1                    32           868              4        20      20   \n",
       "2                    32           868              4        20      20   \n",
       "3                    32          1188              4        20      20   \n",
       "4                    32          1188              4        20      20   \n",
       "\n",
       "   sender_len  paymaster_len   Txn Fee  Gas Used  logIndex  actualGasCost  \\\n",
       "0          20             20  0.022033    398741       245   2.190000e+16   \n",
       "1          20             20  0.004362     87702       231   4.280000e+15   \n",
       "2          20             20  0.003971     87714       273   3.900000e+15   \n",
       "3          20             20  0.008673    161702       429   8.650000e+15   \n",
       "4          20             20  0.006445    127502       393   6.420000e+15   \n",
       "\n",
       "   actualGasUsed  nonce  success   Blockno  DateTime_ts  \n",
       "0         397164    0.0        1  17066994   1681740540  \n",
       "1          86113    1.0        1  17067000   1681740600  \n",
       "2          86125    2.0        1  17067009   1681740720  \n",
       "3         161161    3.0        1  17078992   1681887000  \n",
       "4         126973    4.0        1  17079029   1681887420  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Multiplexon/Desktop/data/2/total_selected_augmented.csv', sep=',')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 0) Imports =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# ===== 1) Load data ===== \n",
    "csv_path = r\"C:/Users/Multiplexon/Desktop/data/2/total_selected_augmented.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "features = [\n",
    "    'Transaction Hash_len', 'Original_len', 'signature_len',\n",
    "    'From_len', 'To_len', 'sender_len', 'paymaster_len',\n",
    "    'Txn Fee', 'logIndex', 'actualGasCost',\n",
    "    'actualGasUsed', 'nonce', 'success', 'Blockno', 'DateTime_ts'\n",
    "]\n",
    "X = df[features].reset_index(drop=True).astype(float)\n",
    "y = df['Gas Used'].astype(float).reset_index(drop=True)\n",
    "\n",
    "# (Tu·ª≥ ch·ªçn) log-transform target n·∫øu skew m·∫°nh\n",
    "USE_LOG_TARGET = False\n",
    "y_trainable = np.log1p(y) if USE_LOG_TARGET else y.copy()\n",
    "\n",
    "# ===== 2) Search space =====\n",
    "def base_space():\n",
    "    return {\n",
    "        'depth': scope.int(hp.quniform('depth', 4, 10, 1)),\n",
    "        'l2_leaf_reg': hp.loguniform('l2_leaf_reg', np.log(1e-2), np.log(1e2)),\n",
    "        'iterations': scope.int(hp.quniform('iterations', 400, 2000, 50)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "        'bootstrap_type': hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "        'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "        'bagging_temperature': hp.uniform('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': hp.uniform('random_strength', 0.0, 5.0),\n",
    "        'rsm': hp.uniform('rsm', 0.6, 1.0),\n",
    "        'leaf_estimation_iterations': scope.int(hp.quniform('leaf_estimation_iterations', 1, 20, 1)),\n",
    "    }\n",
    "\n",
    "def trust_space(center, delta=0.25):\n",
    "    def clamp(v, lo, hi): \n",
    "        return float(max(lo, min(hi, v)))\n",
    "    return {\n",
    "        'depth': scope.int(hp.quniform(\n",
    "            'depth',\n",
    "            max(4, int(center['depth']) - 1),\n",
    "            min(10, int(center['depth']) + 1), 1\n",
    "        )),\n",
    "        'l2_leaf_reg': hp.loguniform(\n",
    "            'l2_leaf_reg',\n",
    "            np.log(clamp(center['l2_leaf_reg'] * (1 - delta), 1e-2, 1e2)),\n",
    "            np.log(clamp(center['l2_leaf_reg'] * (1 + delta), 1e-2, 1e2))\n",
    "        ),\n",
    "        'iterations': scope.int(hp.quniform(\n",
    "            'iterations',\n",
    "            clamp(center['iterations'] - 300, 200, 3000),\n",
    "            clamp(center['iterations'] + 300, 200, 3000), 50\n",
    "        )),\n",
    "        'learning_rate': hp.loguniform(\n",
    "            'learning_rate',\n",
    "            np.log(clamp(center['learning_rate'] * (1 - delta), 0.005, 0.3)),\n",
    "            np.log(clamp(center['learning_rate'] * (1 + delta), 0.005, 0.3))\n",
    "        ),\n",
    "        'bootstrap_type': hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "        'subsample': hp.uniform(\n",
    "            'subsample',\n",
    "            clamp(center.get('subsample', 0.8) - delta, 0.5, 1.0),\n",
    "            clamp(center.get('subsample', 0.8) + delta, 0.5, 1.0)\n",
    "        ),\n",
    "        'bagging_temperature': hp.uniform(\n",
    "            'bagging_temperature',\n",
    "            clamp(center.get('bagging_temperature', 0.5) - delta, 0.0, 1.0),\n",
    "            clamp(center.get('bagging_temperature', 0.5) + delta, 0.0, 1.0)\n",
    "        ),\n",
    "        'random_strength': hp.uniform(\n",
    "            'random_strength',\n",
    "            clamp(center.get('random_strength', 1.0) - 2*delta, 0.0, 10.0),\n",
    "            clamp(center.get('random_strength', 1.0) + 2*delta, 0.0, 10.0)\n",
    "        ),\n",
    "        'rsm': hp.uniform(\n",
    "            'rsm',\n",
    "            clamp(center.get('rsm', 0.8) - delta, 0.5, 1.0),\n",
    "            clamp(center.get('rsm', 0.8) + delta, 0.5, 1.0)\n",
    "        ),\n",
    "        'leaf_estimation_iterations': scope.int(hp.quniform(\n",
    "            'leaf_estimation_iterations',\n",
    "            max(1, int(center.get('leaf_estimation_iterations', 10)) - 5),\n",
    "            min(32, int(center.get('leaf_estimation_iterations', 10)) + 5), 1\n",
    "        )),\n",
    "    }\n",
    "\n",
    "# ===== 3) Cross-validation objective (scaled per fold cho c·∫£ X & y) =====\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def cv_metrics(params):\n",
    "    p = params.copy()\n",
    "    p['depth'] = int(p['depth'])\n",
    "    p['iterations'] = int(p['iterations'])\n",
    "    p['leaf_estimation_iterations'] = int(p['leaf_estimation_iterations'])\n",
    "    p['subsample'] = float(p['subsample'])\n",
    "    p['rsm'] = float(p['rsm'])\n",
    "\n",
    "    rmse_list, mse_list, mae_list, r2_list = [], [], [], []\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        X_tr, X_va = X.iloc[tr_idx].values, X.iloc[va_idx].values\n",
    "        y_tr, y_va = y_trainable.iloc[tr_idx].values, y_trainable.iloc[va_idx].values\n",
    "\n",
    "        # scale per fold\n",
    "        scaler_X = MinMaxScaler()\n",
    "        X_tr_s = scaler_X.fit_transform(X_tr)\n",
    "        X_va_s = scaler_X.transform(X_va)\n",
    "\n",
    "        scaler_y = MinMaxScaler()\n",
    "        y_tr_s = scaler_y.fit_transform(y_tr.reshape(-1, 1)).ravel()\n",
    "        y_va_s = scaler_y.transform(y_va.reshape(-1, 1)).ravel()\n",
    "\n",
    "        kwargs = dict(\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='R2',\n",
    "            iterations=p['iterations'],\n",
    "            learning_rate=float(p['learning_rate']),\n",
    "            depth=p['depth'],\n",
    "            l2_leaf_reg=float(p['l2_leaf_reg']),\n",
    "            random_strength=float(p['random_strength']),\n",
    "            rsm=float(p['rsm']),\n",
    "            leaf_estimation_iterations=p['leaf_estimation_iterations'],\n",
    "            random_seed=42,\n",
    "            verbose=False,\n",
    "            allow_writing_files=False\n",
    "        )\n",
    "        if p['bootstrap_type'] == 'Bayesian':\n",
    "            kwargs.update(bootstrap_type='Bayesian',\n",
    "                          bagging_temperature=float(p['bagging_temperature']))\n",
    "        else:\n",
    "            kwargs.update(bootstrap_type='Bernoulli',\n",
    "                          subsample=float(p['subsample']))\n",
    "\n",
    "        model = CatBoostRegressor(**kwargs)\n",
    "        model.fit(X_tr_s, y_tr_s, eval_set=(X_va_s, y_va_s),\n",
    "                  use_best_model=True, early_stopping_rounds=200)\n",
    "\n",
    "        preds_s = model.predict(X_va_s)\n",
    "\n",
    "        mse  = mean_squared_error(y_va_s, preds_s)\n",
    "        rmse = float(np.sqrt(mse))\n",
    "        mae  = float(mean_absolute_error(y_va_s, preds_s))\n",
    "        r2   = float(r2_score(y_va_s, preds_s))\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse_list,\n",
    "        'mse' : mse_list,\n",
    "        'mae' : mae_list,\n",
    "        'r2'  : r2_list,\n",
    "        'mean_r2': float(np.mean(r2_list))\n",
    "    }\n",
    "\n",
    "def objective(params):\n",
    "    out = cv_metrics(params)\n",
    "    if out is None:\n",
    "        return {'loss': 1e9, 'status': STATUS_OK}\n",
    "    return {\n",
    "        'loss': float(1.0 - out['mean_r2']),\n",
    "        'status': STATUS_OK,\n",
    "        'metrics': out,\n",
    "        'params': params\n",
    "    }\n",
    "\n",
    "# ===== 4) Bayesian Optimization + Trust Region =====\n",
    "TOTAL_EVALS = 30   # tƒÉng l√™n 60/120 n·∫øu mu·ªën\n",
    "STEP = 30\n",
    "TOP_K = 10\n",
    "trials = Trials()\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for i in range(0, TOTAL_EVALS, STEP):\n",
    "    if i == 0:\n",
    "        space = base_space()\n",
    "    else:\n",
    "        past = [t for t in trials.trials if 'loss' in t['result']]\n",
    "        past = sorted(past, key=lambda t: t['result']['loss'])\n",
    "        topk = past[: min(TOP_K, len(past))]\n",
    "        center = {}\n",
    "        for k in ['depth','l2_leaf_reg','iterations','learning_rate','subsample',\n",
    "                  'bagging_temperature','random_strength','rsm','leaf_estimation_iterations']:\n",
    "            vals = [t['result']['params'][k] for t in topk if k in t['result']['params']]\n",
    "            center[k] = float(np.mean(vals)) if len(vals) else {\n",
    "                'learning_rate':0.05,'subsample':0.8,'bagging_temperature':0.5,\n",
    "                'random_strength':1.0,'rsm':0.8,'leaf_estimation_iterations':10\n",
    "            }.get(k, 8.0)\n",
    "        space = trust_space(center, delta=0.25)\n",
    "\n",
    "    fmin(fn=objective, space=space, algo=tpe.suggest,\n",
    "         max_evals=i + STEP, trials=trials, rstate=rng)\n",
    "\n",
    "# ===== 5) Best trial =====\n",
    "best_trial = min(trials.trials, key=lambda t: t['result']['loss'])\n",
    "best_r2_scaled = 1.0 - best_trial['result']['loss']\n",
    "best_params = best_trial['result']['params']\n",
    "\n",
    "print(\"\\nüèÜ Best R¬≤ (CV mean, scaled y):\", best_r2_scaled)\n",
    "print(\"üîß Best params:\", best_params)\n",
    "\n",
    "# ===== 6) Re-evaluate BEST PARAMS per fold =====\n",
    "mse_scores, mae_scores, rmse_scores, r2_scores = [], [], [], []\n",
    "p = dict(best_params)\n",
    "p['depth'] = int(p['depth'])\n",
    "p['iterations'] = int(p['iterations'])\n",
    "p['leaf_estimation_iterations'] = int(p['leaf_estimation_iterations'])\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X), start=1):\n",
    "    X_tr, X_va = X.iloc[tr_idx].values, X.iloc[va_idx].values\n",
    "    y_tr, y_va = y_trainable.iloc[tr_idx].values, y_trainable.iloc[va_idx].values\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    X_tr_s = scaler_X.fit_transform(X_tr)\n",
    "    X_va_s = scaler_X.transform(X_va)\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    y_tr_s = scaler_y.fit_transform(y_tr.reshape(-1, 1)).ravel()\n",
    "    y_va_s = scaler_y.transform(y_va.reshape(-1, 1)).ravel()\n",
    "\n",
    "    params = dict(\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='R2',\n",
    "        iterations=p['iterations'],\n",
    "        learning_rate=float(p['learning_rate']),\n",
    "        depth=p['depth'],\n",
    "        l2_leaf_reg=float(p['l2_leaf_reg']),\n",
    "        random_strength=float(p['random_strength']),\n",
    "        rsm=float(p['rsm']),\n",
    "        leaf_estimation_iterations=p['leaf_estimation_iterations'],\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        allow_writing_files=False,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    if p['bootstrap_type'] == 'Bayesian':\n",
    "        params.update(bootstrap_type='Bayesian',\n",
    "                      bagging_temperature=float(p['bagging_temperature']))\n",
    "    else:\n",
    "        params.update(bootstrap_type='Bernoulli',\n",
    "                      subsample=float(p['subsample']))\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_tr_s, y_tr_s, eval_set=(X_va_s, y_va_s),\n",
    "              early_stopping_rounds=200)\n",
    "    preds_s = model.predict(X_va_s)\n",
    "\n",
    "    mse  = mean_squared_error(y_va_s, preds_s)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_va_s, preds_s)\n",
    "    r2   = r2_score(y_va_s, preds_s)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f\"Fold {fold} - (scaled) \"\n",
    "          f\"MSE: {mse:.6f} | MAE: {mae:.6f} | RMSE: {rmse:.6f} | R¬≤: {r2:.6f}\")\n",
    "\n",
    "print(\"\\n=== K·∫øt qu·∫£ trung b√¨nh (SCALED) ===\")\n",
    "print(f\"Avg MSE : {np.mean(mse_scores):.6f}\")\n",
    "print(f\"Avg MAE : {np.mean(mae_scores):.6f}\")\n",
    "print(f\"Avg RMSE: {np.mean(rmse_scores):.6f}\")\n",
    "print(f\"Avg R¬≤  : {np.mean(r2_scores):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20 -> RMSE=0.004404 | MSE=0.000026 | MAE=0.000726 | R2=0.952829\n",
      "Epoch 02/20 -> RMSE=0.005114 | MSE=0.000033 | MAE=0.000741 | R2=0.943892\n",
      "Epoch 03/20 -> RMSE=0.004888 | MSE=0.000028 | MAE=0.000729 | R2=0.949204\n",
      "Epoch 04/20 -> RMSE=0.004679 | MSE=0.000026 | MAE=0.000804 | R2=0.952704\n",
      "Epoch 05/20 -> RMSE=0.004558 | MSE=0.000026 | MAE=0.000692 | R2=0.953883\n",
      "Epoch 06/20 -> RMSE=0.004767 | MSE=0.000026 | MAE=0.000695 | R2=0.951835\n",
      "Epoch 07/20 -> RMSE=0.004557 | MSE=0.000025 | MAE=0.000693 | R2=0.954250\n",
      "Epoch 08/20 -> RMSE=0.005137 | MSE=0.000030 | MAE=0.000733 | R2=0.942760\n",
      "Epoch 09/20 -> RMSE=0.004938 | MSE=0.000028 | MAE=0.000748 | R2=0.947127\n",
      "Epoch 10/20 -> RMSE=0.004408 | MSE=0.000025 | MAE=0.000697 | R2=0.958188\n",
      "Epoch 11/20 -> RMSE=0.004250 | MSE=0.000022 | MAE=0.000682 | R2=0.961882\n",
      "Epoch 12/20 -> RMSE=0.004604 | MSE=0.000027 | MAE=0.000689 | R2=0.954734\n",
      "Epoch 13/20 -> RMSE=0.004745 | MSE=0.000027 | MAE=0.000701 | R2=0.951734\n",
      "Epoch 14/20 -> RMSE=0.004824 | MSE=0.000028 | MAE=0.000722 | R2=0.948421\n",
      "Epoch 15/20 -> RMSE=0.004568 | MSE=0.000025 | MAE=0.000683 | R2=0.954432\n",
      "Epoch 16/20 -> RMSE=0.004719 | MSE=0.000025 | MAE=0.000693 | R2=0.951900\n",
      "Epoch 17/20 -> RMSE=0.004685 | MSE=0.000029 | MAE=0.000703 | R2=0.946755\n",
      "Epoch 18/20 -> RMSE=0.004686 | MSE=0.000025 | MAE=0.000687 | R2=0.953575\n",
      "Epoch 19/20 -> RMSE=0.004843 | MSE=0.000026 | MAE=0.000691 | R2=0.950424\n",
      "Epoch 20/20 -> RMSE=0.004865 | MSE=0.000027 | MAE=0.000848 | R2=0.948457\n",
      "\n",
      "Final mean on MinMax-scaled y [RMSE, MSE, MAE, R2]:\n",
      "[4.71201502e-03 2.65819638e-05 7.17878871e-04 9.51449280e-01]\n",
      "\n",
      "Per-epoch metrics (rows) on MinMax-scaled y [RMSE, MSE, MAE, R2]:\n",
      "[[4.40446410e-03 2.64070070e-05 7.26154994e-04 9.52829289e-01]\n",
      " [5.11410268e-03 3.27751324e-05 7.40826663e-04 9.43892365e-01]\n",
      " [4.88755557e-03 2.78436132e-05 7.29474027e-04 9.49204239e-01]\n",
      " [4.67899239e-03 2.58692702e-05 8.03644121e-04 9.52703546e-01]\n",
      " [4.55823972e-03 2.56210767e-05 6.92242563e-04 9.53882993e-01]\n",
      " [4.76714836e-03 2.59269027e-05 6.95347558e-04 9.51834560e-01]\n",
      " [4.55669746e-03 2.53862556e-05 6.93260377e-04 9.54249677e-01]\n",
      " [5.13696662e-03 2.97264702e-05 7.32765218e-04 9.42759817e-01]\n",
      " [4.93769744e-03 2.78246623e-05 7.48274543e-04 9.47126712e-01]\n",
      " [4.40775337e-03 2.48076552e-05 6.96920278e-04 9.58187999e-01]\n",
      " [4.25014434e-03 2.16509762e-05 6.81661479e-04 9.61882406e-01]\n",
      " [4.60403863e-03 2.67530397e-05 6.88727377e-04 9.54734337e-01]\n",
      " [4.74457804e-03 2.65778497e-05 7.01269784e-04 9.51734385e-01]\n",
      " [4.82449148e-03 2.76943507e-05 7.22336961e-04 9.48420569e-01]\n",
      " [4.56834691e-03 2.45437905e-05 6.83053742e-04 9.54431970e-01]\n",
      " [4.71938495e-03 2.49622113e-05 6.92593838e-04 9.51900436e-01]\n",
      " [4.68532320e-03 2.90106715e-05 7.02666895e-04 9.46754937e-01]\n",
      " [4.68597122e-03 2.50092271e-05 6.86633431e-04 9.53574792e-01]\n",
      " [4.84344663e-03 2.60698118e-05 6.91424523e-04 9.50423519e-01]\n",
      " [4.86495732e-03 2.71793010e-05 8.48299052e-04 9.48457063e-01]]\n"
     ]
    }
   ],
   "source": [
    "# ================== CONFIG ==================\n",
    "EPOCHS = 20\n",
    "K = 10\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ================== BEST PARAMS (t·ª´ Hyperopt) ==================\n",
    "best_params = {\n",
    "    'bagging_temperature': 0.03808810504137822,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'depth': 9,\n",
    "    'iterations': 1150,\n",
    "    'l2_leaf_reg': 3.157088896921137,\n",
    "    'leaf_estimation_iterations': 18,\n",
    "    'learning_rate': 0.04688120366273992,\n",
    "    'random_strength': 2.0533400767421526,\n",
    "    'rsm': 0.683305874834135,\n",
    "    'subsample': 0.908911282734798\n",
    "}\n",
    "\n",
    "# √âP KI·ªÇU & L√ÄM S·∫†CH PARAMS\n",
    "p = dict(best_params)\n",
    "p['depth'] = int(p.get('depth', 8))\n",
    "p['iterations'] = int(p.get('iterations', 5000))\n",
    "p['leaf_estimation_iterations'] = int(p.get('leaf_estimation_iterations', 10))\n",
    "for k in ['learning_rate','l2_leaf_reg','random_strength','bagging_temperature','rsm','subsample']:\n",
    "    if k in p:\n",
    "        p[k] = float(p[k])\n",
    "btype = p.get('bootstrap_type', 'Bayesian')\n",
    "\n",
    "def build_kwargs(seed_offset: int):\n",
    "    kwargs = dict(\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='R2',\n",
    "        iterations=p['iterations'],\n",
    "        learning_rate=p['learning_rate'],\n",
    "        depth=p['depth'],\n",
    "        l2_leaf_reg=p['l2_leaf_reg'],\n",
    "        random_strength=p['random_strength'],\n",
    "        leaf_estimation_iterations=p['leaf_estimation_iterations'],\n",
    "        random_seed=SEED + seed_offset,\n",
    "        allow_writing_files=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "    # rsm: m·ªôt s·ªë phi√™n b·∫£n CatBoost kh√¥ng h·ªó tr·ª£ ‚Üí s·∫Ω th·ª≠/lo·∫°i ·ªü d∆∞·ªõi\n",
    "    if 'rsm' in p:\n",
    "        kwargs['rsm'] = p['rsm']\n",
    "\n",
    "    if btype == 'Bayesian':\n",
    "        kwargs.update(bootstrap_type='Bayesian',\n",
    "                      bagging_temperature=p.get('bagging_temperature', 1.0))\n",
    "    else:\n",
    "        kwargs.update(bootstrap_type='Bernoulli',\n",
    "                      subsample=p.get('subsample', 0.8))\n",
    "    return kwargs\n",
    "\n",
    "# ================== 1) LOAD & PREP ==================\n",
    "df = pd.read_csv(r'C:/Users/Multiplexon/Desktop/data/2/total_selected_augmented.csv')\n",
    "\n",
    "features = [\n",
    "    'Transaction Hash_len', 'Original_len', 'signature_len', 'From_len', 'To_len',\n",
    "    'sender_len', 'paymaster_len', 'Txn Fee', 'logIndex', 'actualGasCost',\n",
    "    'actualGasUsed', 'nonce', 'success', 'Blockno', 'DateTime_ts'\n",
    "]\n",
    "target = 'Gas Used'\n",
    "\n",
    "X_raw = df[features].copy()\n",
    "y_raw = df[target].astype(float).copy()\n",
    "\n",
    "# N·∫øu b·∫°n c·∫ßn hold-out cho Hyperopt, gi·ªØ block sau; kh√¥ng d√πng ·ªü Repeated K-Fold\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=SEED\n",
    ")\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X_train_s = x_scaler.fit_transform(X_train)\n",
    "X_val_s   = x_scaler.transform(X_val)\n",
    "y_train_s = y_scaler.fit_transform(y_train.values.reshape(-1,1)).ravel()\n",
    "y_val_s   = y_scaler.transform(y_val.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# D·ªÆ LI·ªÜU D√ôNG CHO REPEATED K-FOLD (to√†n b·ªô t·∫≠p)\n",
    "X = X_raw.copy()\n",
    "y_trainable = y_raw.copy()\n",
    "\n",
    "# ================== 2) REPEATED K-FOLD ==================\n",
    "cats = np.zeros((EPOCHS, 4))  # [RMSE, MSE, MAE, R2] tr√™n thang MinMax-scaled\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    kf_rep = KFold(n_splits=K, shuffle=True, random_state=SEED + ep)\n",
    "\n",
    "    rmse_list, mse_list, mae_list, r2_list = [], [], [], []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf_rep.split(X), start=1):\n",
    "        X_tr, X_va = X.iloc[tr_idx].values, X.iloc[va_idx].values\n",
    "        y_tr, y_va = y_trainable.iloc[tr_idx].values, y_trainable.iloc[va_idx].values\n",
    "\n",
    "        # SCALE trong t·ª´ng fold ƒë·ªÉ tr√°nh leakage\n",
    "        sx = MinMaxScaler()\n",
    "        X_tr_s = sx.fit_transform(X_tr)\n",
    "        X_va_s = sx.transform(X_va)\n",
    "\n",
    "        sy = MinMaxScaler()\n",
    "        y_tr_s = sy.fit_transform(y_tr.reshape(-1, 1)).ravel()\n",
    "        y_va_s = sy.transform(y_va.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Build model (th·ª≠ rsm, n·∫øu l·ªói th√¨ b·ªè rsm)\n",
    "        kwargs = build_kwargs(ep)\n",
    "        try:\n",
    "            model = CatBoostRegressor(**kwargs)\n",
    "        except Exception as e:\n",
    "            if \"Unknown parameter\" in str(e) and \"rsm\" in str(e):\n",
    "                kwargs.pop('rsm', None)\n",
    "                model = CatBoostRegressor(**kwargs)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        model.fit(\n",
    "            X_tr_s, y_tr_s,\n",
    "            eval_set=(X_va_s, y_va_s),\n",
    "            early_stopping_rounds=200,\n",
    "            use_best_model=True,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        preds_s = model.predict(X_va_s)\n",
    "\n",
    "        # Metrics tr√™n thang MinMax-scaled c·ªßa y\n",
    "        mse  = mean_squared_error(y_va_s, preds_s)\n",
    "        rmse = float(np.sqrt(mse))\n",
    "        mae  = mean_absolute_error(y_va_s, preds_s)\n",
    "        r2   = r2_score(y_va_s, preds_s)\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    # L∆∞u mean metrics c·ªßa epoch n√†y (qua K folds)\n",
    "    cats[ep, :] = [\n",
    "        np.mean(rmse_list),\n",
    "        np.mean(mse_list),\n",
    "        np.mean(mae_list),\n",
    "        np.mean(r2_list)\n",
    "    ]\n",
    "    print(f\"Epoch {ep+1:02d}/{EPOCHS} -> RMSE={cats[ep,0]:.6f} | MSE={cats[ep,1]:.6f} | MAE={cats[ep,2]:.6f} | R2={cats[ep,3]:.6f}\")\n",
    "\n",
    "# ================== 3) TRUNG B√åNH CU·ªêI ==================\n",
    "final_mean = np.mean(cats, axis=0)\n",
    "print(\"\\nFinal mean on MinMax-scaled y [RMSE, MSE, MAE, R2]:\")\n",
    "print(final_mean)\n",
    "print(\"\\nPer-epoch metrics (rows) on MinMax-scaled y [RMSE, MSE, MAE, R2]:\")\n",
    "print(cats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
