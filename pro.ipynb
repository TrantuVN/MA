{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, STATUS_FAIL, Trials, space_eval\n",
    "import pandas as pd\n",
    "from hyperopt.pyll import scope\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction Hash_len</th>\n",
       "      <th>Original_len</th>\n",
       "      <th>signature_len</th>\n",
       "      <th>From_len</th>\n",
       "      <th>To_len</th>\n",
       "      <th>sender_len</th>\n",
       "      <th>paymaster_len</th>\n",
       "      <th>Txn Fee</th>\n",
       "      <th>Gas Used</th>\n",
       "      <th>logIndex</th>\n",
       "      <th>actualGasCost</th>\n",
       "      <th>actualGasUsed</th>\n",
       "      <th>nonce</th>\n",
       "      <th>success</th>\n",
       "      <th>Blockno</th>\n",
       "      <th>DateTime_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>964</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>398741</td>\n",
       "      <td>245</td>\n",
       "      <td>2.190000e+16</td>\n",
       "      <td>397164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17066994</td>\n",
       "      <td>1681740540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>868</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>87702</td>\n",
       "      <td>231</td>\n",
       "      <td>4.280000e+15</td>\n",
       "      <td>86113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17067000</td>\n",
       "      <td>1681740600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>868</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>87714</td>\n",
       "      <td>273</td>\n",
       "      <td>3.900000e+15</td>\n",
       "      <td>86125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17067009</td>\n",
       "      <td>1681740720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1188</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>161702</td>\n",
       "      <td>429</td>\n",
       "      <td>8.650000e+15</td>\n",
       "      <td>161161</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17078992</td>\n",
       "      <td>1681887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1188</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>127502</td>\n",
       "      <td>393</td>\n",
       "      <td>6.420000e+15</td>\n",
       "      <td>126973</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17079029</td>\n",
       "      <td>1681887420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction Hash_len  Original_len  signature_len  From_len  To_len  \\\n",
       "0                    32           964              4        20      20   \n",
       "1                    32           868              4        20      20   \n",
       "2                    32           868              4        20      20   \n",
       "3                    32          1188              4        20      20   \n",
       "4                    32          1188              4        20      20   \n",
       "\n",
       "   sender_len  paymaster_len   Txn Fee  Gas Used  logIndex  actualGasCost  \\\n",
       "0          20             20  0.022033    398741       245   2.190000e+16   \n",
       "1          20             20  0.004362     87702       231   4.280000e+15   \n",
       "2          20             20  0.003971     87714       273   3.900000e+15   \n",
       "3          20             20  0.008673    161702       429   8.650000e+15   \n",
       "4          20             20  0.006445    127502       393   6.420000e+15   \n",
       "\n",
       "   actualGasUsed  nonce  success   Blockno  DateTime_ts  \n",
       "0         397164    0.0        1  17066994   1681740540  \n",
       "1          86113    1.0        1  17067000   1681740600  \n",
       "2          86125    2.0        1  17067009   1681740720  \n",
       "3         161161    3.0        1  17078992   1681887000  \n",
       "4         126973    4.0        1  17079029   1681887420  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Multiplexon/Desktop/data/2/total_selected_augmented.csv', sep=',')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [2:25:54<00:00, 291.83s/trial, best loss: 0.047170710942521454] \n",
      "\n",
      "🏆 Best R² (CV mean, scaled y): 0.9528292890574785\n",
      "🔧 Best params: {'bagging_temperature': 0.03808810504137822, 'bootstrap_type': 'Bayesian', 'depth': 9, 'iterations': 1150, 'l2_leaf_reg': 3.157088896921137, 'leaf_estimation_iterations': 18, 'learning_rate': 0.04688120366273992, 'random_strength': 2.0533400767421526, 'rsm': 0.683305874834135, 'subsample': 0.908911282734798}\n",
      "Fold 1 - (scaled) MSE: 0.000015 | MAE: 0.000649 | RMSE: 0.003849 | R²: 0.967753\n",
      "Fold 2 - (scaled) MSE: 0.000090 | MAE: 0.001217 | RMSE: 0.009490 | R²: 0.838412\n",
      "Fold 3 - (scaled) MSE: 0.000004 | MAE: 0.000616 | RMSE: 0.001939 | R²: 0.991723\n",
      "Fold 4 - (scaled) MSE: 0.000012 | MAE: 0.000630 | RMSE: 0.003471 | R²: 0.976417\n",
      "Fold 5 - (scaled) MSE: 0.000003 | MAE: 0.000618 | RMSE: 0.001829 | R²: 0.993262\n",
      "Fold 6 - (scaled) MSE: 0.000023 | MAE: 0.000746 | RMSE: 0.004818 | R²: 0.968091\n",
      "Fold 7 - (scaled) MSE: 0.000008 | MAE: 0.000652 | RMSE: 0.002817 | R²: 0.985449\n",
      "Fold 8 - (scaled) MSE: 0.000004 | MAE: 0.000641 | RMSE: 0.001980 | R²: 0.990382\n",
      "Fold 9 - (scaled) MSE: 0.000082 | MAE: 0.000771 | RMSE: 0.009052 | R²: 0.865492\n",
      "Fold 10 - (scaled) MSE: 0.000023 | MAE: 0.000723 | RMSE: 0.004801 | R²: 0.951311\n",
      "\n",
      "=== Kết quả trung bình (SCALED) ===\n",
      "Avg MSE : 0.000026\n",
      "Avg MAE : 0.000726\n",
      "Avg RMSE: 0.004404\n",
      "Avg R²  : 0.952829\n"
     ]
    }
   ],
   "source": [
    "# ===== 0) Imports =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# ===== 1) Load data ===== \n",
    "csv_path = r\"C:/Users/Multiplexon/Desktop/data/2/total_selected_augmented.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "features = [\n",
    "    'Transaction Hash_len', 'Original_len', 'signature_len',\n",
    "    'From_len', 'To_len', 'sender_len', 'paymaster_len',\n",
    "    'Txn Fee', 'logIndex', 'actualGasCost',\n",
    "    'actualGasUsed', 'nonce', 'success', 'Blockno', 'DateTime_ts'\n",
    "]\n",
    "X = df[features].reset_index(drop=True).astype(float)\n",
    "y = df['Gas Used'].astype(float).reset_index(drop=True)\n",
    "\n",
    "# (Tuỳ chọn) log-transform target nếu skew mạnh\n",
    "USE_LOG_TARGET = False\n",
    "y_trainable = np.log1p(y) if USE_LOG_TARGET else y.copy()\n",
    "\n",
    "# ===== 2) Search space =====\n",
    "def base_space():\n",
    "    return {\n",
    "        'depth': scope.int(hp.quniform('depth', 4, 10, 1)),\n",
    "        'l2_leaf_reg': hp.loguniform('l2_leaf_reg', np.log(1e-2), np.log(1e2)),\n",
    "        'iterations': scope.int(hp.quniform('iterations', 400, 2000, 50)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "        'bootstrap_type': hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "        'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "        'bagging_temperature': hp.uniform('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': hp.uniform('random_strength', 0.0, 5.0),\n",
    "        'rsm': hp.uniform('rsm', 0.6, 1.0),\n",
    "        'leaf_estimation_iterations': scope.int(hp.quniform('leaf_estimation_iterations', 1, 20, 1)),\n",
    "    }\n",
    "\n",
    "def trust_space(center, delta=0.25):\n",
    "    def clamp(v, lo, hi): \n",
    "        return float(max(lo, min(hi, v)))\n",
    "    return {\n",
    "        'depth': scope.int(hp.quniform(\n",
    "            'depth',\n",
    "            max(4, int(center['depth']) - 1),\n",
    "            min(10, int(center['depth']) + 1), 1\n",
    "        )),\n",
    "        'l2_leaf_reg': hp.loguniform(\n",
    "            'l2_leaf_reg',\n",
    "            np.log(clamp(center['l2_leaf_reg'] * (1 - delta), 1e-2, 1e2)),\n",
    "            np.log(clamp(center['l2_leaf_reg'] * (1 + delta), 1e-2, 1e2))\n",
    "        ),\n",
    "        'iterations': scope.int(hp.quniform(\n",
    "            'iterations',\n",
    "            clamp(center['iterations'] - 300, 200, 3000),\n",
    "            clamp(center['iterations'] + 300, 200, 3000), 50\n",
    "        )),\n",
    "        'learning_rate': hp.loguniform(\n",
    "            'learning_rate',\n",
    "            np.log(clamp(center['learning_rate'] * (1 - delta), 0.005, 0.3)),\n",
    "            np.log(clamp(center['learning_rate'] * (1 + delta), 0.005, 0.3))\n",
    "        ),\n",
    "        'bootstrap_type': hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "        'subsample': hp.uniform(\n",
    "            'subsample',\n",
    "            clamp(center.get('subsample', 0.8) - delta, 0.5, 1.0),\n",
    "            clamp(center.get('subsample', 0.8) + delta, 0.5, 1.0)\n",
    "        ),\n",
    "        'bagging_temperature': hp.uniform(\n",
    "            'bagging_temperature',\n",
    "            clamp(center.get('bagging_temperature', 0.5) - delta, 0.0, 1.0),\n",
    "            clamp(center.get('bagging_temperature', 0.5) + delta, 0.0, 1.0)\n",
    "        ),\n",
    "        'random_strength': hp.uniform(\n",
    "            'random_strength',\n",
    "            clamp(center.get('random_strength', 1.0) - 2*delta, 0.0, 10.0),\n",
    "            clamp(center.get('random_strength', 1.0) + 2*delta, 0.0, 10.0)\n",
    "        ),\n",
    "        'rsm': hp.uniform(\n",
    "            'rsm',\n",
    "            clamp(center.get('rsm', 0.8) - delta, 0.5, 1.0),\n",
    "            clamp(center.get('rsm', 0.8) + delta, 0.5, 1.0)\n",
    "        ),\n",
    "        'leaf_estimation_iterations': scope.int(hp.quniform(\n",
    "            'leaf_estimation_iterations',\n",
    "            max(1, int(center.get('leaf_estimation_iterations', 10)) - 5),\n",
    "            min(32, int(center.get('leaf_estimation_iterations', 10)) + 5), 1\n",
    "        )),\n",
    "    }\n",
    "\n",
    "# ===== 3) Cross-validation objective (scaled per fold cho cả X & y) =====\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def cv_metrics(params):\n",
    "    p = params.copy()\n",
    "    p['depth'] = int(p['depth'])\n",
    "    p['iterations'] = int(p['iterations'])\n",
    "    p['leaf_estimation_iterations'] = int(p['leaf_estimation_iterations'])\n",
    "    p['subsample'] = float(p['subsample'])\n",
    "    p['rsm'] = float(p['rsm'])\n",
    "\n",
    "    rmse_list, mse_list, mae_list, r2_list = [], [], [], []\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        X_tr, X_va = X.iloc[tr_idx].values, X.iloc[va_idx].values\n",
    "        y_tr, y_va = y_trainable.iloc[tr_idx].values, y_trainable.iloc[va_idx].values\n",
    "\n",
    "        # scale per fold\n",
    "        scaler_X = MinMaxScaler()\n",
    "        X_tr_s = scaler_X.fit_transform(X_tr)\n",
    "        X_va_s = scaler_X.transform(X_va)\n",
    "\n",
    "        scaler_y = MinMaxScaler()\n",
    "        y_tr_s = scaler_y.fit_transform(y_tr.reshape(-1, 1)).ravel()\n",
    "        y_va_s = scaler_y.transform(y_va.reshape(-1, 1)).ravel()\n",
    "\n",
    "        kwargs = dict(\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='R2',\n",
    "            iterations=p['iterations'],\n",
    "            learning_rate=float(p['learning_rate']),\n",
    "            depth=p['depth'],\n",
    "            l2_leaf_reg=float(p['l2_leaf_reg']),\n",
    "            random_strength=float(p['random_strength']),\n",
    "            rsm=float(p['rsm']),\n",
    "            leaf_estimation_iterations=p['leaf_estimation_iterations'],\n",
    "            random_seed=42,\n",
    "            verbose=False,\n",
    "            allow_writing_files=False\n",
    "        )\n",
    "        if p['bootstrap_type'] == 'Bayesian':\n",
    "            kwargs.update(bootstrap_type='Bayesian',\n",
    "                          bagging_temperature=float(p['bagging_temperature']))\n",
    "        else:\n",
    "            kwargs.update(bootstrap_type='Bernoulli',\n",
    "                          subsample=float(p['subsample']))\n",
    "\n",
    "        model = CatBoostRegressor(**kwargs)\n",
    "        model.fit(X_tr_s, y_tr_s, eval_set=(X_va_s, y_va_s),\n",
    "                  use_best_model=True, early_stopping_rounds=200)\n",
    "\n",
    "        preds_s = model.predict(X_va_s)\n",
    "\n",
    "        mse  = mean_squared_error(y_va_s, preds_s)\n",
    "        rmse = float(np.sqrt(mse))\n",
    "        mae  = float(mean_absolute_error(y_va_s, preds_s))\n",
    "        r2   = float(r2_score(y_va_s, preds_s))\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse_list,\n",
    "        'mse' : mse_list,\n",
    "        'mae' : mae_list,\n",
    "        'r2'  : r2_list,\n",
    "        'mean_r2': float(np.mean(r2_list))\n",
    "    }\n",
    "\n",
    "def objective(params):\n",
    "    out = cv_metrics(params)\n",
    "    if out is None:\n",
    "        return {'loss': 1e9, 'status': STATUS_OK}\n",
    "    return {\n",
    "        'loss': float(1.0 - out['mean_r2']),\n",
    "        'status': STATUS_OK,\n",
    "        'metrics': out,\n",
    "        'params': params\n",
    "    }\n",
    "\n",
    "# ===== 4) Bayesian Optimization + Trust Region =====\n",
    "TOTAL_EVALS = 30   # tăng lên 60/120 nếu muốn\n",
    "STEP = 30\n",
    "TOP_K = 10\n",
    "trials = Trials()\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for i in range(0, TOTAL_EVALS, STEP):\n",
    "    if i == 0:\n",
    "        space = base_space()\n",
    "    else:\n",
    "        past = [t for t in trials.trials if 'loss' in t['result']]\n",
    "        past = sorted(past, key=lambda t: t['result']['loss'])\n",
    "        topk = past[: min(TOP_K, len(past))]\n",
    "        center = {}\n",
    "        for k in ['depth','l2_leaf_reg','iterations','learning_rate','subsample',\n",
    "                  'bagging_temperature','random_strength','rsm','leaf_estimation_iterations']:\n",
    "            vals = [t['result']['params'][k] for t in topk if k in t['result']['params']]\n",
    "            center[k] = float(np.mean(vals)) if len(vals) else {\n",
    "                'learning_rate':0.05,'subsample':0.8,'bagging_temperature':0.5,\n",
    "                'random_strength':1.0,'rsm':0.8,'leaf_estimation_iterations':10\n",
    "            }.get(k, 8.0)\n",
    "        space = trust_space(center, delta=0.25)\n",
    "\n",
    "    fmin(fn=objective, space=space, algo=tpe.suggest,\n",
    "         max_evals=i + STEP, trials=trials, rstate=rng)\n",
    "\n",
    "# ===== 5) Best trial =====\n",
    "best_trial = min(trials.trials, key=lambda t: t['result']['loss'])\n",
    "best_r2_scaled = 1.0 - best_trial['result']['loss']\n",
    "best_params = best_trial['result']['params']\n",
    "\n",
    "print(\"\\n🏆 Best R² (CV mean, scaled y):\", best_r2_scaled)\n",
    "print(\"🔧 Best params:\", best_params)\n",
    "\n",
    "# ===== 6) Re-evaluate BEST PARAMS per fold =====\n",
    "mse_scores, mae_scores, rmse_scores, r2_scores = [], [], [], []\n",
    "p = dict(best_params)\n",
    "p['depth'] = int(p['depth'])\n",
    "p['iterations'] = int(p['iterations'])\n",
    "p['leaf_estimation_iterations'] = int(p['leaf_estimation_iterations'])\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X), start=1):\n",
    "    X_tr, X_va = X.iloc[tr_idx].values, X.iloc[va_idx].values\n",
    "    y_tr, y_va = y_trainable.iloc[tr_idx].values, y_trainable.iloc[va_idx].values\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    X_tr_s = scaler_X.fit_transform(X_tr)\n",
    "    X_va_s = scaler_X.transform(X_va)\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    y_tr_s = scaler_y.fit_transform(y_tr.reshape(-1, 1)).ravel()\n",
    "    y_va_s = scaler_y.transform(y_va.reshape(-1, 1)).ravel()\n",
    "\n",
    "    params = dict(\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='R2',\n",
    "        iterations=p['iterations'],\n",
    "        learning_rate=float(p['learning_rate']),\n",
    "        depth=p['depth'],\n",
    "        l2_leaf_reg=float(p['l2_leaf_reg']),\n",
    "        random_strength=float(p['random_strength']),\n",
    "        rsm=float(p['rsm']),\n",
    "        leaf_estimation_iterations=p['leaf_estimation_iterations'],\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        allow_writing_files=False,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    if p['bootstrap_type'] == 'Bayesian':\n",
    "        params.update(bootstrap_type='Bayesian',\n",
    "                      bagging_temperature=float(p['bagging_temperature']))\n",
    "    else:\n",
    "        params.update(bootstrap_type='Bernoulli',\n",
    "                      subsample=float(p['subsample']))\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_tr_s, y_tr_s, eval_set=(X_va_s, y_va_s),\n",
    "              early_stopping_rounds=200)\n",
    "    preds_s = model.predict(X_va_s)\n",
    "\n",
    "    mse  = mean_squared_error(y_va_s, preds_s)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_va_s, preds_s)\n",
    "    r2   = r2_score(y_va_s, preds_s)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f\"Fold {fold} - (scaled) \"\n",
    "          f\"MSE: {mse:.6f} | MAE: {mae:.6f} | RMSE: {rmse:.6f} | R²: {r2:.6f}\")\n",
    "\n",
    "print(\"\\n=== Kết quả trung bình (SCALED) ===\")\n",
    "print(f\"Avg MSE : {np.mean(mse_scores):.6f}\")\n",
    "print(f\"Avg MAE : {np.mean(mae_scores):.6f}\")\n",
    "print(f\"Avg RMSE: {np.mean(rmse_scores):.6f}\")\n",
    "print(f\"Avg R²  : {np.mean(r2_scores):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EVALS = 30   # tăng nếu muốn\n",
    "STEP = 30\n",
    "TOP_K = 10\n",
    "trials = Trials()\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "for i in range(0, TOTAL_EVALS, STEP):\n",
    "    if i == 0:\n",
    "        space = base_space()\n",
    "    else:\n",
    "        past = [t for t in trials.trials if 'loss' in t['result']]\n",
    "        past = sorted(past, key=lambda t: t['result']['loss'])\n",
    "        topk = past[: min(TOP_K, len(past))]\n",
    "        center = {}\n",
    "        for k_ in ['depth','l2_leaf_reg','iterations','learning_rate','subsample',\n",
    "                  'bagging_temperature','random_strength','rsm','leaf_estimation_iterations']:\n",
    "            vals = [t['result']['params'][k_] for t in topk if k_ in t['result']['params']]\n",
    "            center[k_] = float(np.mean(vals)) if len(vals) else {\n",
    "                'learning_rate':0.05,'subsample':0.8,'bagging_temperature':0.5,\n",
    "                'random_strength':1.0,'rsm':0.8,'leaf_estimation_iterations':10\n",
    "            }.get(k_, 8.0)\n",
    "        space = trust_space(center, delta=0.25)\n",
    "\n",
    "    fmin(fn=objective, space=space, algo=tpe.suggest,\n",
    "         max_evals=i + STEP, trials=trials, rstate=rng)\n",
    "\n",
    "# ===== 5) Best trial =====\n",
    "best_trial = min(trials.trials, key=lambda t: t['result']['loss'])\n",
    "best_r2_scaled = 1.0 - best_trial['result']['loss']\n",
    "best_params = best_trial['result']['params']\n",
    "\n",
    "print(\"\\n🏆 Best R² (CV mean, scaled y):\", best_r2_scaled)\n",
    "print(\"🔧 Best params:\", best_params)\n",
    "\n",
    "# ===== 6) Repeated KFold (epochs × k) với Best Params -> cats & final_mean =====\n",
    "EPOCHS = 20\n",
    "K = 10\n",
    "cats = np.zeros((EPOCHS, 4))  # mỗi hàng: [RMSE, MSE, MAE, R2] (trên thang scaled)\n",
    "\n",
    "# ép kiểu bắt buộc\n",
    "p = dict(best_params)\n",
    "p['depth'] = int(p['depth'])\n",
    "p['iterations'] = int(p['iterations'])\n",
    "p['leaf_estimation_iterations'] = int(p['leaf_estimation_iterations'])\n",
    "p['subsample'] = float(p['subsample'])\n",
    "p['rsm'] = float(p['rsm'])\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    kf_rep = KFold(n_splits=K, shuffle=True, random_state=SEED + ep)\n",
    "\n",
    "    rmse_list, mse_list, mae_list, r2_list = [], [], [], []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf_rep.split(X), start=1):\n",
    "        X_tr, X_va = X.iloc[tr_idx].values, X.iloc[va_idx].values\n",
    "        y_tr, y_va = y_trainable.iloc[tr_idx].values, y_trainable.iloc[va_idx].values\n",
    "\n",
    "        # scale per fold\n",
    "        sx = MinMaxScaler()\n",
    "        X_tr_s = sx.fit_transform(X_tr)\n",
    "        X_va_s = sx.transform(X_va)\n",
    "\n",
    "        sy = MinMaxScaler()\n",
    "        y_tr_s = sy.fit_transform(y_tr.reshape(-1, 1)).ravel()\n",
    "        y_va_s = sy.transform(y_va.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # build params\n",
    "        kwargs = dict(\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='R2',\n",
    "            iterations=p['iterations'],\n",
    "            learning_rate=float(p['learning_rate']),\n",
    "            depth=p['depth'],\n",
    "            l2_leaf_reg=float(p['l2_leaf_reg']),\n",
    "            random_strength=float(p['random_strength']),\n",
    "            rsm=float(p['rsm']),\n",
    "            leaf_estimation_iterations=p['leaf_estimation_iterations'],\n",
    "            random_seed=SEED + ep,\n",
    "            verbose=False,\n",
    "            allow_writing_files=False,\n",
    "            use_best_model=True\n",
    "            # GPU? -> task_type='GPU', devices='0'\n",
    "        )\n",
    "        if p['bootstrap_type'] == 'Bayesian':\n",
    "            kwargs.update(bootstrap_type='Bayesian',\n",
    "                          bagging_temperature=float(p['bagging_temperature']))\n",
    "        else:\n",
    "            kwargs.update(bootstrap_type='Bernoulli',\n",
    "                          subsample=float(p['subsample']))\n",
    "\n",
    "        model = CatBoostRegressor(**kwargs)\n",
    "        model.fit(X_tr_s, y_tr_s, eval_set=(X_va_s, y_va_s),\n",
    "                  early_stopping_rounds=200)\n",
    "\n",
    "        preds_s = model.predict(X_va_s)\n",
    "\n",
    "        # metrics trên thang MinMax-scaled của y\n",
    "        mse  = mean_squared_error(y_va_s, preds_s)\n",
    "        rmse = float(np.sqrt(mse))\n",
    "        mae  = mean_absolute_error(y_va_s, preds_s)\n",
    "        r2   = r2_score(y_va_s, preds_s)\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    # lưu mean metrics của epoch này (qua 10 folds)\n",
    "    cats[ep, :] = [\n",
    "        np.mean(rmse_list),\n",
    "        np.mean(mse_list),\n",
    "        np.mean(mae_list),\n",
    "        np.mean(r2_list)\n",
    "    ]\n",
    "    print(f\"Epoch {ep+1:02d}/{EPOCHS} -> RMSE={cats[ep,0]:.6f} | MSE={cats[ep,1]:.6f} | MAE={cats[ep,2]:.6f} | R2={cats[ep,3]:.6f}\")\n",
    "\n",
    "# mean cuối cùng qua tất cả epochs\n",
    "final_mean = np.mean(cats, axis=0)\n",
    "\n",
    "print(\"\\nFinal mean on MinMax-scaled y [RMSE, MSE, MAE, R2]:\")\n",
    "print(final_mean)  # 1 dòng mean cuối cùng\n",
    "print(\"\\nPer-epoch metrics (rows) on MinMax-scaled y [RMSE, MSE, MAE, R2]:\")\n",
    "print(cats)        # bảng (epochs × 4)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
